{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5789bc3-b1ae-42c7-94a8-2ef4f89946fc",
   "metadata": {},
   "source": [
    "# Lesson 4: Persistence and Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da06a64f-a2d5-4a66-8090-9ada0930c684",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3292cc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph-checkpoint-sqlite\n",
      "  Downloading langgraph_checkpoint_sqlite-2.0.3-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting aiosqlite<0.21.0,>=0.20.0 (from langgraph-checkpoint-sqlite)\n",
      "  Downloading aiosqlite-0.20.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from langgraph-checkpoint-sqlite) (2.0.10)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from aiosqlite<0.21.0,>=0.20.0->langgraph-checkpoint-sqlite) (4.12.2)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.2.38 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (0.3.34)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (1.1.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (0.3.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (2.10.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (2.27.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (2.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\chait\\downloads\\chatnet.v2\\chatnetv2\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.10->langgraph-checkpoint-sqlite) (1.3.1)\n",
      "Downloading langgraph_checkpoint_sqlite-2.0.3-py3-none-any.whl (12 kB)\n",
      "Downloading aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: aiosqlite, langgraph-checkpoint-sqlite\n",
      "Successfully installed aiosqlite-0.20.0 langgraph-checkpoint-sqlite-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph-checkpoint-sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c033522-d2fc-41ac-8e3c-5e35872bf88d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 574
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=memory)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_r287', 'function': {'arguments': '{\"query\":\"current weather in san francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 1014, 'total_tokens': 1066, 'completion_time': 0.154603588, 'prompt_time': 0.085667677, 'queue_time': 0.069323831, 'total_time': 0.240271265}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-70d15780-515e-4f82-b3a0-233b094d2e09-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in san francisco'}, 'id': 'call_r287', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1014, 'output_tokens': 52, 'total_tokens': 1066})]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in san francisco'}, 'id': 'call_r287', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739048645, \\'localtime\\': \\'2025-02-08 13:04\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739048400, \\'last_updated\\': \\'2025-02-08 13:00\\', \\'temp_c\\': 11.1, \\'temp_f\\': 52.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 6.7, \\'wind_kph\\': 10.8, \\'wind_degree\\': 351, \\'wind_dir\\': \\'N\\', \\'pressure_mb\\': 1029.0, \\'pressure_in\\': 30.38, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 66, \\'cloud\\': 25, \\'feelslike_c\\': 9.8, \\'feelslike_f\\': 49.7, \\'windchill_c\\': 7.8, \\'windchill_f\\': 46.0, \\'heatindex_c\\': 8.5, \\'heatindex_f\\': 47.3, \\'dewpoint_c\\': 6.2, \\'dewpoint_f\\': 43.2, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 2.9, \\'gust_mph\\': 8.2, \\'gust_kph\\': 13.2}}\"}, {\\'url\\': \\'https://www.weather25.com/north-america/usa/california/san-francisco?page=month&month=February\\', \\'content\\': \\'San Francisco weather in February 2025 | Weather25.com San Francisco weather in February 2025 The average weather in San Francisco in February | San Francisco in February | Temperatures in San Francisco in February Weather in San Francisco in February - FAQ What is the average temperature in San Francisco in February? The average temperature in San Francisco in February is 7/16° C. On average, there are 4 rainy days in San Francisco during February. The weather in San Francisco in February is good. On average, there are 0 snowy days in San Francisco in February. More about the weather in San Francisco San Francisco 14 day weather Long range weather for San Francisco San Francisco weather in March San Francisco Webcam Weather tomorrow Hotels in San Francisco\\'}]', name='tavily_search_results_json', tool_call_id='call_r287')]\n",
      "[AIMessage(content='The current weather in San Francisco is partly cloudy with a temperature of 11.1°C (52°F) and a feels like temperature of 9.8°C (49.7°F). The wind is blowing at 6.7 mph (10.8 kph) from the north, and the humidity is 66%.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 1678, 'total_tokens': 1746, 'completion_time': 0.197600854, 'prompt_time': 0.087744474, 'queue_time': 0.143989327, 'total_time': 0.285345328}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None}, id='run-314a89ca-e4d6-41bd-a67f-283542635dea-0', usage_metadata={'input_tokens': 1678, 'output_tokens': 68, 'total_tokens': 1746})]\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_m95c', 'function': {'arguments': '{\"query\":\"current weather in los angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 1760, 'total_tokens': 1804, 'completion_time': 0.133777399, 'prompt_time': 0.086575298, 'queue_time': 0.14357427, 'total_time': 0.220352697}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-468c04ca-f7ea-4598-86da-263943e86a4b-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in los angeles'}, 'id': 'call_m95c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1760, 'output_tokens': 44, 'total_tokens': 1804})]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in los angeles'}, 'id': 'call_m95c', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.0522, \\'lon\\': -118.2428, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739047993, \\'localtime\\': \\'2025-02-08 12:53\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739047500, \\'last_updated\\': \\'2025-02-08 12:45\\', \\'temp_c\\': 16.7, \\'temp_f\\': 62.1, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Sunny\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 4.0, \\'wind_kph\\': 6.5, \\'wind_degree\\': 252, \\'wind_dir\\': \\'WSW\\', \\'pressure_mb\\': 1020.0, \\'pressure_in\\': 30.12, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 53, \\'cloud\\': 0, \\'feelslike_c\\': 16.7, \\'feelslike_f\\': 62.1, \\'windchill_c\\': 17.4, \\'windchill_f\\': 63.2, \\'heatindex_c\\': 17.5, \\'heatindex_f\\': 63.4, \\'dewpoint_c\\': 5.1, \\'dewpoint_f\\': 41.2, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 4.8, \\'gust_mph\\': 4.6, \\'gust_kph\\': 7.5}}\"}, {\\'url\\': \\'https://weathershogun.com/weather/usa/ca/los-angeles/451/february/2025-02-08\\', \\'content\\': \\'Los Angeles, California Weather: Saturday, February 8, 2025. Cloudy weather, overcast skies with clouds. Day 66°. Night 50°.\\'}]', name='tavily_search_results_json', tool_call_id='call_m95c')]}\n",
      "{'messages': [AIMessage(content='The current weather in Los Angeles is sunny with a temperature of 16.7°C (62.1°F) and a feels like temperature of 16.7°C (62.1°F). The wind is blowing at 4.0 mph (6.5 kph) from the west-southwest, and the humidity is 53%.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 2314, 'total_tokens': 2386, 'completion_time': 0.211814757, 'prompt_time': 0.112966499, 'queue_time': 0.07362702500000001, 'total_time': 0.324781256}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None}, id='run-5d680a73-8781-446c-b711-ea854fb1c7b5-0', usage_metadata={'input_tokens': 2314, 'output_tokens': 72, 'total_tokens': 2386})]}\n",
      "{'messages': [AIMessage(content=\"Los Angeles is warmer, with a temperature of 16.7°C (62.1°F), compared to San Francisco's temperature of 11.1°C (52°F).\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 2400, 'total_tokens': 2437, 'completion_time': 0.111577383, 'prompt_time': 0.120406014, 'queue_time': 0.148659215, 'total_time': 0.231983397}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None}, id='run-086e253f-02a4-4ed1-8438-387c79bb8a51-0', usage_metadata={'input_tokens': 2400, 'output_tokens': 37, 'total_tokens': 2437})]}\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4a3r', 'function': {'arguments': '{\"query\":\"temperature comparison\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 1012, 'total_tokens': 1060, 'completion_time': 0.141634023, 'prompt_time': 0.051132268, 'queue_time': 0.068694072, 'total_time': 0.192766291}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-94828849-f194-4b97-a9d0-94ec1f93cf06-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'temperature comparison'}, 'id': 'call_4a3r', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1012, 'output_tokens': 48, 'total_tokens': 1060})]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'temperature comparison'}, 'id': 'call_4a3r', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content=\"[{'url': 'https://www.metricmetal.com/wp-content/uploads/2017/05/degree_conver_2017.pdf', 'content': 'Fahrenheit & Centigrade Temperature Comparisons. If we do not have what you want we can get it for you from our depot in Europe. Call 1-800-333-4140. 58. -30.'}, {'url': 'https://en.wikipedia.org/wiki/Conversion_of_scales_of_temperature', 'content': 'This is a collection of temperature conversion formulas and comparisons among eight different temperature scales, several of which have long been obsolete.'}]\", name='tavily_search_results_json', tool_call_id='call_4a3r')]}\n",
      "{'messages': [AIMessage(content=\"You didn't provide enough information to determine which one is warmer. Could you please provide more context or clarify your question?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 1209, 'total_tokens': 1234, 'completion_time': 0.075796074, 'prompt_time': 0.070728067, 'queue_time': 0.02298513599999999, 'total_time': 0.146524141}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None}, id='run-3f036729-e1a3-4ac8-9c1f-a79ace048ea9-0', usage_metadata={'input_tokens': 1209, 'output_tokens': 25, 'total_tokens': 1234})]}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatGroq(model=\"llama3-70b-8192\")\n",
    "with SqliteSaver.from_conn_string(\":memory:\") as memory:\n",
    "    abot = Agent(model, [tool], system=prompt, checkpointer=memory)\n",
    "\n",
    "    messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
    "    thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "        for v in event.values():\n",
    "            print(v['messages'])\n",
    "\n",
    "    messages = [HumanMessage(content=\"What about in la?\")]\n",
    "    thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "        for v in event.values():\n",
    "            print(v)\n",
    "\n",
    "    messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "    thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "        for v in event.values():\n",
    "            print(v)    \n",
    "\n",
    "    messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "    thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "    for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "        for v in event.values():\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c583cbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_a0xn', 'function': {'arguments': '{\"query\":\"what was my last question\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 1013, 'total_tokens': 1064, 'completion_time': 0.152530951, 'prompt_time': 0.075628695, 'queue_time': 0.23889469100000002, 'total_time': 0.228159646}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-647c878f-3fd4-4701-bcc5-d015ee9bd13a-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'what was my last question'}, 'id': 'call_a0xn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1013, 'output_tokens': 51, 'total_tokens': 1064})]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'what was my last question'}, 'id': 'call_a0xn', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://community.openai.com/t/chat-ignores-my-last-question-or-comment-and-just-spams-its-previous-answers-at-me/852818\\', \\'content\\': \"ChatGPT seems to treat any follow up question as “I want a full new answer to my original question”. There\\'s no way to ask for clarification. No\"}, {\\'url\\': \\'https://meta.stackexchange.com/questions/166401/is-there-a-way-to-find-my-last-visited-questions\\', \\'content\\': \"There\\'s a record of your actions which you can see by clicking on your profile and going to the Activity tab and clicking All. This nicely\"}]', name='tavily_search_results_json', tool_call_id='call_a0xn')]\n",
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_gwab', 'function': {'arguments': '{\"query\":\"how to find my last question on this platform\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 1220, 'total_tokens': 1268, 'completion_time': 0.13937886, 'prompt_time': 0.070653832, 'queue_time': 0.158174658, 'total_time': 0.210032692}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ab4e343e-af65-4c07-81af-3455806c259c-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'how to find my last question on this platform'}, 'id': 'call_gwab', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1220, 'output_tokens': 48, 'total_tokens': 1268})]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'how to find my last question on this platform'}, 'id': 'call_gwab', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://answers.microsoft.com/en-us/msoffice/forum/all/how-do-i-locate-my-previous-questions-in-the/7120c32b-07d5-47d5-8f57-8f96457c4694\\', \\'content\\': \"Click on your name in the upper right corner. Select \\'My Profile\\' from the dropdown menu. Direct link: Profile --- Best wishes, HansV\"}, {\\'url\\': \\'https://brainly.com/question/42242865\\', \\'content\\': \\'Go to your profile and view question history. B. Use the search function with your username. C. Click on your previous questions in the feed. D.\\'}]', name='tavily_search_results_json', tool_call_id='call_gwab')]\n",
      "[AIMessage(content='It seems like I don\\'t need to call another tool to answer your original question \"what was my last question?\" since we\\'ve already had this conversation.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 1437, 'total_tokens': 1469, 'completion_time': 0.096128039, 'prompt_time': 0.0797981, 'queue_time': 0.142417085, 'total_time': 0.175926139}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None}, id='run-6d58201a-00d0-4b0e-b531-f1b84c76d5fd-0', usage_metadata={'input_tokens': 1437, 'output_tokens': 32, 'total_tokens': 1469})]\n"
     ]
    }
   ],
   "source": [
    "with SqliteSaver.from_conn_string(\":memory:\") as memory:\n",
    "    abot = Agent(model, [tool], system=prompt, checkpointer=memory)\n",
    "\n",
    "    messages = [HumanMessage(content=\"what was my last question?\")]\n",
    "    thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "        for v in event.values():\n",
    "            print(v['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace59a36-3941-459e-b9d1-ac5a4a1ed3ae",
   "metadata": {},
   "source": [
    "## Streaming tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph.checkpoint.aiosqlite'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiosqlite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncSqliteSaver\n\u001b[0;32m      3\u001b[0m memory \u001b[38;5;241m=\u001b[39m AsyncSqliteSaver\u001b[38;5;241m.\u001b[39mfrom_conn_string(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:memory:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m abot \u001b[38;5;241m=\u001b[39m Agent(model, [tool], system\u001b[38;5;241m=\u001b[39mprompt, checkpointer\u001b[38;5;241m=\u001b[39mmemory)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langgraph.checkpoint.aiosqlite'"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f303b1-a4d0-408c-8cc0-515ff980717f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatnetv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
