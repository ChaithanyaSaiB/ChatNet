{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LANGCHAIN_TRACING_V2=true\n",
      "env: LANGCHAIN_API_KEY=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\n"
     ]
    }
   ],
   "source": [
    "%env LANGCHAIN_TRACING_V2=true\n",
    "%env LANGCHAIN_API_KEY=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\n",
    "# The below examples use the OpenAI API, though it's not necessary in general\n",
    "# %env OPENAI_API_KEY=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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getenv(\"LANGCHAIN_API_KEY\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class ChatOpenRouter(ChatOpenAI):\n",
    "    def __init__(self, model_name: str, openai_api_base: str = None, openai_api_key: str = None, **kwargs):\n",
    "        openai_api_base = openai_api_base or \"https://openrouter.ai/api/v1\"\n",
    "        openai_api_key = \"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\"\n",
    "        super().__init__(\n",
    "            openai_api_base=openai_api_base,\n",
    "            openai_api_key=openai_api_key,\n",
    "            model_name=model_name,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='68bf4f4e-841e-4000-ba09-01b1f5fd63be'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ca4e', 'function': {'arguments': '{\"query\":\"weather in sf\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 1158, 'total_tokens': 1248, 'completion_time': 0.138129611, 'prompt_time': 0.050602691, 'queue_time': 0.022400335, 'total_time': 0.188732302}, 'model_name': 'mixtral-8x7b-32768', 'system_fingerprint': 'fp_c5f20b5bb1', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-af512c6f-cf0b-40ce-a0d8-f1a76e36bf42-0', tool_calls=[{'name': 'search', 'args': {'query': 'weather in sf'}, 'id': 'call_ca4e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1158, 'output_tokens': 90, 'total_tokens': 1248}),\n",
       "  ToolMessage(content=\"It's 60 degrees and foggy.\", name='search', id='bca4bd7a-c84a-46a3-b99a-b65fbb50cf1e', tool_call_id='call_ca4e'),\n",
       "  AIMessage(content=\"It's 60 degrees and foggy.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 1243, 'total_tokens': 1255, 'completion_time': 0.017091816, 'prompt_time': 0.054130354, 'queue_time': 0.023184460999999996, 'total_time': 0.07122217}, 'model_name': 'mixtral-8x7b-32768', 'system_fingerprint': 'fp_c5f20b5bb1', 'finish_reason': 'stop', 'logprobs': None}, id='run-4b875900-af92-435d-a219-a11ed2b22209-0', usage_metadata={'input_tokens': 1243, 'output_tokens': 12, 'total_tokens': 1255})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Call to surf the web.\"\"\"\n",
    "    if \"sf\" in query.lower() or \"san francisco\" in query.lower():\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    return \"It's 90 degrees and sunny.\"\n",
    "\n",
    "tools = [search]\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "model = ChatGroq(name=\"llama3-70b-8192\", temperature=0).bind_tools(tools)\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state['messages']\n",
    "\n",
    "    # Invoking `model` will automatically infer the correct tracing context\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(\"__start__\", \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    ")\n",
    "workflow.add_edge(\"tools\", 'agent')\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "final_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatnetv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
